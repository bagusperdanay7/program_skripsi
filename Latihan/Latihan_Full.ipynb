{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case Folding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contoh Data Ulasan:\n",
      "Saya paling senang blnja online disini,slama 7thn blnja disini gk pernah tertipu,sellernya jujur2 & ramah serta CS nya juga sopan klo kita ada kendala. Beda ama toko online shop sebelah saya 2x ketipu dionline shop sebelah 2 online shope.. disini saya nyaman blnja apapun itu.... cuma 1 yg bikin kesal tentang SERBU SERU blm prnh dpt barang ðŸ˜‚ðŸ˜‚ðŸ˜‚ \n",
      "\n",
      "aplikasi bermanfaat. sangat membantu di jaman now. mudah dan cepat \n",
      "\n",
      "top banget dah fitur dan harganya bener2 sangat bermanfaat sukses selalu untuk bukalapak excelent nomor wahid \n",
      "\n",
      "Pelayanan bukalapak untuk penjual sangat jelek, bukadompet saya dibekukan udah beberapa hari ini padahal udah komplain berulang kali dan memberikan bukti transaksi yang valid tapi tetep aja masih dibekukan dan hasil penjualan jadi ditahan, mohon aktifkan kembali bukadompet saya!!! \n",
      "\n",
      "Bukalapak bagus barang sesuai pengiriman cepat...tingkatkan min biar makin semangat belanja d bukalapak nya wkwkwk \n",
      "\n",
      "================================================================================================================================== \n",
      "\n",
      "Setelah Case Folding:\n",
      "saya paling senang blnja online disini,slama 7thn blnja disini gk pernah tertipu,sellernya jujur2 & ramah serta cs nya juga sopan klo kita ada kendala. beda ama toko online shop sebelah saya 2x ketipu dionline shop sebelah 2 online shope.. disini saya nyaman blnja apapun itu.... cuma 1 yg bikin kesal tentang serbu seru blm prnh dpt barang ðŸ˜‚ðŸ˜‚ðŸ˜‚ \n",
      "\n",
      "aplikasi bermanfaat. sangat membantu di jaman now. mudah dan cepat \n",
      "\n",
      "top banget dah fitur dan harganya bener2 sangat bermanfaat sukses selalu untuk bukalapak excelent nomor wahid \n",
      "\n",
      "pelayanan bukalapak untuk penjual sangat jelek, bukadompet saya dibekukan udah beberapa hari ini padahal udah komplain berulang kali dan memberikan bukti transaksi yang valid tapi tetep aja masih dibekukan dan hasil penjualan jadi ditahan, mohon aktifkan kembali bukadompet saya!!! \n",
      "\n",
      "bukalapak bagus barang sesuai pengiriman cepat...tingkatkan min biar makin semangat belanja d bukalapak nya wkwkwk\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ulasan_1 = \"Saya paling senang blnja online disini,slama 7thn blnja disini gk pernah tertipu,sellernya jujur2 & ramah serta CS nya juga sopan klo kita ada kendala. Beda ama toko online shop sebelah saya 2x ketipu dionline shop sebelah 2 online shope.. disini saya nyaman blnja apapun itu.... cuma 1 yg bikin kesal tentang SERBU SERU blm prnh dpt barang ðŸ˜‚ðŸ˜‚ðŸ˜‚\"\n",
    "ulasan_2 = \"aplikasi bermanfaat. sangat membantu di jaman now. mudah dan cepat\" \n",
    "ulasan_3 = \"top banget dah fitur dan harganya bener2 sangat bermanfaat sukses selalu untuk bukalapak excelent nomor wahid\" \n",
    "ulasan_4 = \"Pelayanan bukalapak untuk penjual sangat jelek, bukadompet saya dibekukan udah beberapa hari ini padahal udah komplain berulang kali dan memberikan bukti transaksi yang valid tapi tetep aja masih dibekukan dan hasil penjualan jadi ditahan, mohon aktifkan kembali bukadompet saya!!!\" \n",
    "ulasan_5 = \"Bukalapak bagus barang sesuai pengiriman cepat...tingkatkan min biar makin semangat belanja d bukalapak nya wkwkwk\" \n",
    "\n",
    "print(f\"\"\"Contoh Data Ulasan:\n",
    "{ulasan_1} \\n\n",
    "{ulasan_2} \\n\n",
    "{ulasan_3} \\n\n",
    "{ulasan_4} \\n\n",
    "{ulasan_5} \n",
    "\"\"\")\n",
    "\n",
    "def case_folding(teks):\n",
    "    teks = teks.lower()\n",
    "    return teks\n",
    "\n",
    "ulasan_1 = case_folding(ulasan_1)\n",
    "ulasan_2 = case_folding(ulasan_2)\n",
    "ulasan_3 = case_folding(ulasan_3)\n",
    "ulasan_4 = case_folding(ulasan_4)\n",
    "ulasan_5 = case_folding(ulasan_5)\n",
    "\n",
    "print(\"=\"*130, '\\n')\n",
    "print(f\"\"\"Setelah Case Folding:\n",
    "{ulasan_1} \\n\n",
    "{ulasan_2} \\n\n",
    "{ulasan_3} \\n\n",
    "{ulasan_4} \\n\n",
    "{ulasan_5}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebelum Filtering:\n",
      "saya paling senang blnja online disini,slama 7thn blnja disini gk pernah tertipu,sellernya jujur2 & ramah serta cs nya juga sopan klo kita ada kendala. beda ama toko online shop sebelah saya 2x ketipu dionline shop sebelah 2 online shope.. disini saya nyaman blnja apapun itu.... cuma 1 yg bikin kesal tentang serbu seru blm prnh dpt barang ðŸ˜‚ðŸ˜‚ðŸ˜‚ \n",
      "\n",
      "aplikasi bermanfaat. sangat membantu di jaman now. mudah dan cepat \n",
      "\n",
      "top banget dah fitur dan harganya bener2 sangat bermanfaat sukses selalu untuk bukalapak excelent nomor wahid \n",
      "\n",
      "pelayanan bukalapak untuk penjual sangat jelek, bukadompet saya dibekukan udah beberapa hari ini padahal udah komplain berulang kali dan memberikan bukti transaksi yang valid tapi tetep aja masih dibekukan dan hasil penjualan jadi ditahan, mohon aktifkan kembali bukadompet saya!!! \n",
      "\n",
      "bukalapak bagus barang sesuai pengiriman cepat...tingkatkan min biar makin semangat belanja d bukalapak nya wkwkwk \n",
      "\n",
      "================================================================================================================================== \n",
      "\n",
      "Setelah Filtering:\n",
      "saya paling senang blnja online disini slama thn blnja disini gk pernah tertipu sellernya jujur ramah serta cs nya juga sopan klo kita ada kendala beda ama toko online shop sebelah saya  ketipu dionline shop sebelah online shope disini saya nyaman blnja apapun itu cuma yg bikin kesal tentang serbu seru blm prnh dpt barang \n",
      "\n",
      "aplikasi bermanfaat sangat membantu di jaman now mudah dan cepat \n",
      "\n",
      "top banget dah fitur dan harganya bener sangat bermanfaat sukses selalu untuk bukalapak excelent nomor wahid \n",
      "\n",
      "pelayanan bukalapak untuk penjual sangat jelek bukadompet saya dibekukan udah beberapa hari ini padahal udah komplain berulang kali dan memberikan bukti transaksi yang valid tapi tetep aja masih dibekukan dan hasil penjualan jadi ditahan mohon aktifkan kembali bukadompet saya \n",
      "\n",
      "bukalapak bagus barang sesuai pengiriman cepat tingkatkan min biar makin semangat belanja  bukalapak nya wkwkwk\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "# filtering\n",
    "def filtering(teks):\n",
    "\n",
    "    # Step 1 - Menghilangkan url\n",
    "    teks = re.sub(r'http\\S+', '', teks)\n",
    "    teks = re.sub(r'https\\S+', '', teks)\n",
    "\n",
    "    # Step 2 - Menghilangkan spasi dan tanda baca kecuali underscore\n",
    "    teks = re.sub(r'''         \n",
    "                \\W+ \n",
    "                \\s*     \n",
    "                ''',    \n",
    "                ' ',    \n",
    "                teks,\n",
    "                flags=re.VERBOSE)\n",
    "\n",
    "    # Step 3 - Menghilangkan angka\n",
    "    teks = ' '.join(re.sub(r\"\\d+\", \"\", teks).split())\n",
    "\n",
    "    # Step 4 - Menghilangkan Unicode, spasi tab, dan, new line \n",
    "    teks = teks.replace('\\\\t',\" \").replace('\\\\n',\" \").replace('\\\\u',\" \")   \n",
    "\n",
    "    # Step 5 - Encoding dan decode ascii (konversi byte)\n",
    "    teks = teks.encode('ascii', 'replace').decode('ascii')\n",
    "    \n",
    "    # Step 6 - menghilangkan white space lebih\n",
    "    teks = ' '.join(re.sub(\"([@#][A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)\",\" \", teks).split())\n",
    "\n",
    "    hilangkan_tanda_baca = string.punctuation\n",
    "\n",
    "    # Step 7 - menghilangkan semua tanda baca\n",
    "    teks = teks.translate(str.maketrans(' ', ' ', hilangkan_tanda_baca))\n",
    "\n",
    "    # Step 8 - Menghilangkan satu karakter\n",
    "    teks = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", teks)\n",
    "    return teks\n",
    "\n",
    "\n",
    "print(f\"\"\"Sebelum Filtering:\n",
    "{ulasan_1} \\n\n",
    "{ulasan_2} \\n\n",
    "{ulasan_3} \\n\n",
    "{ulasan_4} \\n\n",
    "{ulasan_5} \n",
    "\"\"\")\n",
    "\n",
    "ulasan_1 = filtering(ulasan_1)\n",
    "ulasan_2 = filtering(ulasan_2)\n",
    "ulasan_3 = filtering(ulasan_3)\n",
    "ulasan_4 = filtering(ulasan_4)\n",
    "ulasan_5 = filtering(ulasan_5)\n",
    "\n",
    "print(\"=\"*130, '\\n')\n",
    "print(f\"\"\"Setelah Filtering:\n",
    "{ulasan_1} \\n\n",
    "{ulasan_2} \\n\n",
    "{ulasan_3} \\n\n",
    "{ulasan_4} \\n\n",
    "{ulasan_5}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebelum Word Normalization:\n",
      "saya paling senang blnja online disini slama thn blnja disini gk pernah tertipu sellernya jujur ramah serta cs nya juga sopan klo kita ada kendala beda ama toko online shop sebelah saya  ketipu dionline shop sebelah online shope disini saya nyaman blnja apapun itu cuma yg bikin kesal tentang serbu seru blm prnh dpt barang \n",
      "\n",
      "aplikasi bermanfaat sangat membantu di jaman now mudah dan cepat \n",
      "\n",
      "top banget dah fitur dan harganya bener sangat bermanfaat sukses selalu untuk bukalapak excelent nomor wahid \n",
      "\n",
      "pelayanan bukalapak untuk penjual sangat jelek bukadompet saya dibekukan udah beberapa hari ini padahal udah komplain berulang kali dan memberikan bukti transaksi yang valid tapi tetep aja masih dibekukan dan hasil penjualan jadi ditahan mohon aktifkan kembali bukadompet saya \n",
      "\n",
      "bukalapak bagus barang sesuai pengiriman cepat tingkatkan min biar makin semangat belanja  bukalapak nya wkwkwk \n",
      "\n",
      "================================================================================================================================== \n",
      "\n",
      "Setelah Word Normalization:\n",
      "saya paling senang belanja online di sini selama tahun belanja di sini tidak pernah tertipu penjualnya jujur ramah serta layanan pelanggan nya juga sopan kalau kita ada kendala beda sama toko online shop sebelah saya tertipu dionline shop sebelah online shope di sini saya nyaman belanja apapun itu cuma yang membuat kesal tentang serbu seru belum pernah dapat barang \n",
      "\n",
      "aplikasi bermanfaat sangat membantu di jaman sekarang mudah dan cepat \n",
      "\n",
      "top sangat sudah fitur dan harganya benar sangat bermanfaat sukses selalu untuk bukalapak excelent nomor wahid \n",
      "\n",
      "pelayanan bukalapak untuk penjual sangat jelek bukadompet saya dibekukan sudah beberapa hari ini padahal sudah komplain berulang kali dan memberikan bukti transaksi yang valid tapi tetap saja masih dibekukan dan hasil penjualan jadi ditahan mohon aktifkan kembali bukadompet saya \n",
      "\n",
      "bukalapak bagus barang sesuai pengiriman cepat tingkatkan admin biar makin semangat belanja bukalapak nya hahaha\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "kamus_informal_to_formal = pd.read_csv('kamus_normalization.tsv',sep='\\t')\n",
    "kamus_informal_to_formal = kamus_informal_to_formal.iloc[:,1:3]\n",
    "\n",
    "\n",
    "kamus_normalisasi = {}\n",
    "\n",
    "# penambahan yang tidak ada di kamus sebelumnya, wahid -> satu\n",
    "kamus_normalisasi = {\"x\": \"kali\", \"now\": \"sekarang\", \"min\": \"admin\"}\n",
    "\n",
    "for index, row in kamus_informal_to_formal.iterrows():\n",
    "    if row[0] not in kamus_normalisasi:\n",
    "        kamus_normalisasi[row[0]] = row[1]\n",
    "\n",
    "\n",
    "# kamus_normalisasi # tampilkan kamus\n",
    "\n",
    "# convert string to list of words\n",
    "def word_normalization(teks):\n",
    "    # mensplit\n",
    "    teks = teks.split()\n",
    "\n",
    "    teks = [kamus_normalisasi[word] if word in kamus_normalisasi else word for word in teks]\n",
    "\n",
    "    teks = ' '.join(teks)\n",
    "\n",
    "    return teks\n",
    "\n",
    "\n",
    "print(f\"\"\"Sebelum Word Normalization:\n",
    "{ulasan_1} \\n\n",
    "{ulasan_2} \\n\n",
    "{ulasan_3} \\n\n",
    "{ulasan_4} \\n\n",
    "{ulasan_5} \n",
    "\"\"\")\n",
    "\n",
    "ulasan_1 = word_normalization(ulasan_1)\n",
    "ulasan_2 = word_normalization(ulasan_2)\n",
    "ulasan_3 = word_normalization(ulasan_3)\n",
    "ulasan_4 = word_normalization(ulasan_4)\n",
    "ulasan_5 = word_normalization(ulasan_5)\n",
    "\n",
    "print(\"=\"*130, '\\n')\n",
    "print(f\"\"\"Setelah Word Normalization:\n",
    "{ulasan_1} \\n\n",
    "{ulasan_2} \\n\n",
    "{ulasan_3} \\n\n",
    "{ulasan_4} \\n\n",
    "{ulasan_5}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Convert Negation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebelum Convert Negation:\n",
      "saya paling senang belanja online di sini selama tahun belanja di sini tidak pernah tertipu penjualnya jujur ramah serta layanan pelanggan nya juga sopan kalau kita ada kendala beda sama toko online shop sebelah saya tertipu dionline shop sebelah online shope di sini saya nyaman belanja apapun itu cuma yang membuat kesal tentang serbu seru belum pernah dapat barang \n",
      "\n",
      "aplikasi bermanfaat sangat membantu di jaman sekarang mudah dan cepat \n",
      "\n",
      "top sangat sudah fitur dan harganya benar sangat bermanfaat sukses selalu untuk bukalapak excelent nomor wahid \n",
      "\n",
      "pelayanan bukalapak untuk penjual sangat jelek bukadompet saya dibekukan sudah beberapa hari ini padahal sudah komplain berulang kali dan memberikan bukti transaksi yang valid tapi tetap saja masih dibekukan dan hasil penjualan jadi ditahan mohon aktifkan kembali bukadompet saya \n",
      "\n",
      "bukalapak bagus barang sesuai pengiriman cepat tingkatkan admin biar makin semangat belanja bukalapak nya hahaha \n",
      "\n",
      "================================================================================================================================== \n",
      "\n",
      "Setelah Convert Negation:\n",
      "saya paling senang belanja online di sini selama tahun belanja di sini tidak_pernah tertipu penjualnya jujur ramah serta layanan pelanggan nya juga sopan kalau kita ada kendala beda sama toko online shop sebelah saya tertipu dionline shop sebelah online shope di sini saya nyaman belanja apapun itu cuma yang membuat kesal tentang serbu seru belum_pernah dapat barang \n",
      "\n",
      "aplikasi bermanfaat sangat membantu di jaman sekarang mudah dan cepat \n",
      "\n",
      "top sangat sudah fitur dan harganya benar sangat bermanfaat sukses selalu untuk bukalapak excelent nomor wahid \n",
      "\n",
      "pelayanan bukalapak untuk penjual sangat jelek bukadompet saya dibekukan sudah beberapa hari ini padahal sudah komplain berulang kali dan memberikan bukti transaksi yang valid tapi tetap saja masih dibekukan dan hasil penjualan jadi ditahan mohon aktifkan kembali bukadompet saya \n",
      "\n",
      "bukalapak bagus barang sesuai pengiriman cepat tingkatkan admin biar makin semangat belanja bukalapak nya hahaha\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# kata tak\n",
    "def convert_negation(teks):\n",
    "    convert_tidak = teks.replace(\"tidak \", \"tidak_\")\n",
    "    convert_belum = convert_tidak.replace(\"belum \", \"belum_\")\n",
    "    convert_jangan = convert_belum.replace(\"jangan \", \"jangan_\")\n",
    "    convert_tak = convert_jangan.replace(\"tak \", \"tak_\")\n",
    "    last_convert = convert_tak.replace(\"bukan \", \"bukan_\")\n",
    "\n",
    "    return last_convert\n",
    "\n",
    "print(f\"\"\"Sebelum Convert Negation:\n",
    "{ulasan_1} \\n\n",
    "{ulasan_2} \\n\n",
    "{ulasan_3} \\n\n",
    "{ulasan_4} \\n\n",
    "{ulasan_5} \n",
    "\"\"\")\n",
    "\n",
    "ulasan_1 = convert_negation(ulasan_1)\n",
    "ulasan_2 = convert_negation(ulasan_2)\n",
    "ulasan_3 = convert_negation(ulasan_3)\n",
    "ulasan_4 = convert_negation(ulasan_4)\n",
    "ulasan_5 = convert_negation(ulasan_5)\n",
    "\n",
    "print(\"=\"*130, '\\n')\n",
    "print(f\"\"\"Setelah Convert Negation:\n",
    "{ulasan_1} \\n\n",
    "{ulasan_2} \\n\n",
    "{ulasan_3} \\n\n",
    "{ulasan_4} \\n\n",
    "{ulasan_5}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebelum Tokenization:\n",
      "saya paling senang belanja online di sini selama tahun belanja di sini tidak_pernah tertipu penjualnya jujur ramah serta layanan pelanggan nya juga sopan kalau kita ada kendala beda sama toko online shop sebelah saya tertipu dionline shop sebelah online shope di sini saya nyaman belanja apapun itu cuma yang membuat kesal tentang serbu seru belum_pernah dapat barang \n",
      "\n",
      "aplikasi bermanfaat sangat membantu di jaman sekarang mudah dan cepat \n",
      "\n",
      "top sangat sudah fitur dan harganya benar sangat bermanfaat sukses selalu untuk bukalapak excelent nomor wahid \n",
      "\n",
      "pelayanan bukalapak untuk penjual sangat jelek bukadompet saya dibekukan sudah beberapa hari ini padahal sudah komplain berulang kali dan memberikan bukti transaksi yang valid tapi tetap saja masih dibekukan dan hasil penjualan jadi ditahan mohon aktifkan kembali bukadompet saya \n",
      "\n",
      "bukalapak bagus barang sesuai pengiriman cepat tingkatkan admin biar makin semangat belanja bukalapak nya hahaha \n",
      "\n",
      "================================================================================================================================== \n",
      "\n",
      "Setelah Tokenization:\n",
      "['saya', 'paling', 'senang', 'belanja', 'online', 'di', 'sini', 'selama', 'tahun', 'belanja', 'di', 'sini', 'tidak_pernah', 'tertipu', 'penjualnya', 'jujur', 'ramah', 'serta', 'layanan', 'pelanggan', 'nya', 'juga', 'sopan', 'kalau', 'kita', 'ada', 'kendala', 'beda', 'sama', 'toko', 'online', 'shop', 'sebelah', 'saya', 'tertipu', 'dionline', 'shop', 'sebelah', 'online', 'shope', 'di', 'sini', 'saya', 'nyaman', 'belanja', 'apapun', 'itu', 'cuma', 'yang', 'membuat', 'kesal', 'tentang', 'serbu', 'seru', 'belum_pernah', 'dapat', 'barang'] \n",
      "\n",
      "['aplikasi', 'bermanfaat', 'sangat', 'membantu', 'di', 'jaman', 'sekarang', 'mudah', 'dan', 'cepat'] \n",
      "\n",
      "['top', 'sangat', 'sudah', 'fitur', 'dan', 'harganya', 'benar', 'sangat', 'bermanfaat', 'sukses', 'selalu', 'untuk', 'bukalapak', 'excelent', 'nomor', 'wahid'] \n",
      "\n",
      "['pelayanan', 'bukalapak', 'untuk', 'penjual', 'sangat', 'jelek', 'bukadompet', 'saya', 'dibekukan', 'sudah', 'beberapa', 'hari', 'ini', 'padahal', 'sudah', 'komplain', 'berulang', 'kali', 'dan', 'memberikan', 'bukti', 'transaksi', 'yang', 'valid', 'tapi', 'tetap', 'saja', 'masih', 'dibekukan', 'dan', 'hasil', 'penjualan', 'jadi', 'ditahan', 'mohon', 'aktifkan', 'kembali', 'bukadompet', 'saya'] \n",
      "\n",
      "['bukalapak', 'bagus', 'barang', 'sesuai', 'pengiriman', 'cepat', 'tingkatkan', 'admin', 'biar', 'makin', 'semangat', 'belanja', 'bukalapak', 'nya', 'hahaha']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def tokenization(teks):\n",
    "    teks = word_tokenize(teks)\n",
    "    return teks\n",
    "\n",
    "print(f\"\"\"Sebelum Tokenization:\n",
    "{ulasan_1} \\n\n",
    "{ulasan_2} \\n\n",
    "{ulasan_3} \\n\n",
    "{ulasan_4} \\n\n",
    "{ulasan_5} \n",
    "\"\"\")\n",
    "\n",
    "ulasan_1 = tokenization(ulasan_1)\n",
    "ulasan_2 = tokenization(ulasan_2)\n",
    "ulasan_3 = tokenization(ulasan_3)\n",
    "ulasan_4 = tokenization(ulasan_4)\n",
    "ulasan_5 = tokenization(ulasan_5)\n",
    "\n",
    "print(\"=\"*130, '\\n')\n",
    "print(f\"\"\"Setelah Tokenization:\n",
    "{ulasan_1} \\n\n",
    "{ulasan_2} \\n\n",
    "{ulasan_3} \\n\n",
    "{ulasan_4} \\n\n",
    "{ulasan_5}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stopword Removal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebelum Stopword Removal:\n",
      "['saya', 'paling', 'senang', 'belanja', 'online', 'di', 'sini', 'selama', 'tahun', 'belanja', 'di', 'sini', 'tidak_pernah', 'tertipu', 'penjualnya', 'jujur', 'ramah', 'serta', 'layanan', 'pelanggan', 'nya', 'juga', 'sopan', 'kalau', 'kita', 'ada', 'kendala', 'beda', 'sama', 'toko', 'online', 'shop', 'sebelah', 'saya', 'tertipu', 'dionline', 'shop', 'sebelah', 'online', 'shope', 'di', 'sini', 'saya', 'nyaman', 'belanja', 'apapun', 'itu', 'cuma', 'yang', 'membuat', 'kesal', 'tentang', 'serbu', 'seru', 'belum_pernah', 'dapat', 'barang'] \n",
      "\n",
      "['aplikasi', 'bermanfaat', 'sangat', 'membantu', 'di', 'jaman', 'sekarang', 'mudah', 'dan', 'cepat'] \n",
      "\n",
      "['top', 'sangat', 'sudah', 'fitur', 'dan', 'harganya', 'benar', 'sangat', 'bermanfaat', 'sukses', 'selalu', 'untuk', 'bukalapak', 'excelent', 'nomor', 'wahid'] \n",
      "\n",
      "['pelayanan', 'bukalapak', 'untuk', 'penjual', 'sangat', 'jelek', 'bukadompet', 'saya', 'dibekukan', 'sudah', 'beberapa', 'hari', 'ini', 'padahal', 'sudah', 'komplain', 'berulang', 'kali', 'dan', 'memberikan', 'bukti', 'transaksi', 'yang', 'valid', 'tapi', 'tetap', 'saja', 'masih', 'dibekukan', 'dan', 'hasil', 'penjualan', 'jadi', 'ditahan', 'mohon', 'aktifkan', 'kembali', 'bukadompet', 'saya'] \n",
      "\n",
      "['bukalapak', 'bagus', 'barang', 'sesuai', 'pengiriman', 'cepat', 'tingkatkan', 'admin', 'biar', 'makin', 'semangat', 'belanja', 'bukalapak', 'nya', 'hahaha'] \n",
      "\n",
      "================================================================================================================================== \n",
      "\n",
      "Setelah Stopword Removal:\n",
      "['senang', 'belanja', 'online', 'belanja', 'tidak_pernah', 'tertipu', 'penjualnya', 'jujur', 'ramah', 'layanan', 'pelanggan', 'sopan', 'kendala', 'beda', 'toko', 'online', 'shop', 'sebelah', 'tertipu', 'dionline', 'shop', 'sebelah', 'online', 'shope', 'nyaman', 'belanja', 'apapun', 'kesal', 'serbu', 'seru', 'belum_pernah', 'barang'] \n",
      "\n",
      "['aplikasi', 'bermanfaat', 'membantu', 'jaman', 'mudah', 'cepat'] \n",
      "\n",
      "['top', 'fitur', 'harganya', 'bermanfaat', 'sukses', 'bukalapak', 'excelent', 'nomor', 'wahid'] \n",
      "\n",
      "['pelayanan', 'bukalapak', 'penjual', 'jelek', 'bukadompet', 'dibekukan', 'komplain', 'berulang', 'bukti', 'transaksi', 'valid', 'dibekukan', 'hasil', 'penjualan', 'ditahan', 'mohon', 'aktifkan', 'bukadompet'] \n",
      "\n",
      "['bukalapak', 'bagus', 'barang', 'sesuai', 'pengiriman', 'cepat', 'tingkatkan', 'admin', 'biar', 'semangat', 'belanja', 'bukalapak', 'hahaha']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = stopwords.words('indonesian')\n",
    "# print(STOPWORDS)\n",
    "STOPWORDS.extend(['kali', 'nya'])\n",
    "# STOPWORDS.extend(['amp','hahaha','ya','bnr','bener','iya','dikit','sih','nya', 'yg', 'dll','gara', 'dan lain', 'dan lain-lain', 'oh','y','g','yes', 'yang','gak','bgt','ku','buat','karena','karna','ga','udah','udh','pas','kalau','kalo','eh','deh','coba','oke','a','aa','aaa','aaaa','aaaaa','huhuhu','hihihi','hahaha','hehehe','he','heh','hehe','si','ah','aja','ni','ini','xixi','da'])\n",
    "\n",
    "stopword_list = set(STOPWORDS)\n",
    "\n",
    "# Kata yang tidak seharusnya dibuang : membuat, dapat\n",
    "# stopword_list.remove(\"dapat\")\n",
    "\n",
    "def stopword_removal(teks):\n",
    "    stopword = []\n",
    "\n",
    "    for word in teks:\n",
    "        if word not in stopword_list:\n",
    "            stopword.append(word)\n",
    "    return stopword\n",
    "\n",
    "print(f\"\"\"Sebelum Stopword Removal:\n",
    "{ulasan_1} \\n\n",
    "{ulasan_2} \\n\n",
    "{ulasan_3} \\n\n",
    "{ulasan_4} \\n\n",
    "{ulasan_5} \n",
    "\"\"\")\n",
    "\n",
    "ulasan_1 = stopword_removal(ulasan_1)\n",
    "ulasan_2 = stopword_removal(ulasan_2)\n",
    "ulasan_3 = stopword_removal(ulasan_3)\n",
    "ulasan_4 = stopword_removal(ulasan_4)\n",
    "ulasan_5 = stopword_removal(ulasan_5)\n",
    "\n",
    "print(\"=\"*130, '\\n')\n",
    "print(f\"\"\"Setelah Stopword Removal:\n",
    "{ulasan_1} \\n\n",
    "{ulasan_2} \\n\n",
    "{ulasan_3} \\n\n",
    "{ulasan_4} \\n\n",
    "{ulasan_5}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemming**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "# from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "# factory = StemmerFactory()\n",
    "# stemmer = factory.create_stemmer()\n",
    "\n",
    "# kalimat = \"'bagus', 'banget', 'kedepannya', 'tolong', 'tingkatkan', 'tampilan', 'ui', 'nya', 'kenyamanan', 'belanja', 'meningkat'\"\n",
    "# hasil = stemmer.stem(kalimat)\n",
    "# word_tokens = word_tokenize(hasil)\n",
    "# print(word_tokens)\n",
    "\n",
    "# ouput\n",
    "# andi kerap laku transaksi rutin cara daring atau online turut andi belanja online lebih praktis murah"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Word Embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Penambahan Token Aspek**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sebelum Stopword Removal:\n",
      "['senang', 'belanja', 'online', 'belanja', 'tidak_pernah', 'tertipu', 'penjualnya', 'jujur', 'ramah', 'layanan', 'pelanggan', 'sopan', 'kendala', 'beda', 'toko', 'online', 'shop', 'sebelah', 'tertipu', 'dionline', 'shop', 'sebelah', 'online', 'shope', 'nyaman', 'belanja', 'apapun', 'kesal', 'serbu', 'seru', 'belum_pernah', 'barang'] \n",
      "\n",
      "['aplikasi', 'bermanfaat', 'membantu', 'jaman', 'mudah', 'cepat'] \n",
      "\n",
      "['top', 'fitur', 'harganya', 'bermanfaat', 'sukses', 'bukalapak', 'excelent', 'nomor', 'wahid'] \n",
      "\n",
      "['pelayanan', 'bukalapak', 'penjual', 'jelek', 'bukadompet', 'dibekukan', 'komplain', 'berulang', 'bukti', 'transaksi', 'valid', 'dibekukan', 'hasil', 'penjualan', 'ditahan', 'mohon', 'aktifkan', 'bukadompet'] \n",
      "\n",
      "['bukalapak', 'bagus', 'barang', 'sesuai', 'pengiriman', 'cepat', 'tingkatkan', 'admin', 'biar', 'semangat', 'belanja', 'bukalapak', 'hahaha'] \n",
      "\n",
      "================================================================================================================================== \n",
      "\n",
      "Setelah Stopword Removal:\n",
      "['senang', 'belanja', 'online', 'belanja', 'tidak_pernah', 'tertipu', 'penjualnya', 'jujur', 'ramah', 'layanan', 'pelanggan', 'sopan', 'kendala', 'beda', 'toko', 'online', 'shop', 'sebelah', 'tertipu', 'dionline', 'shop', 'sebelah', 'online', 'shope', 'nyaman', 'belanja', 'apapun', 'kesal', 'serbu', 'seru', 'belum_pernah', 'barang', '<LAYANAN>', '<FITUR>', '<KEBERMANFAATAN>', '<BISNIS>', '<NON ASPEK>'] \n",
      "\n",
      "['aplikasi', 'bermanfaat', 'membantu', 'jaman', 'mudah', 'cepat', '<LAYANAN>', '<FITUR>', '<KEBERMANFAATAN>', '<BISNIS>', '<NON ASPEK>'] \n",
      "\n",
      "['top', 'fitur', 'harganya', 'bermanfaat', 'sukses', 'bukalapak', 'excelent', 'nomor', 'wahid', '<LAYANAN>', '<FITUR>', '<KEBERMANFAATAN>', '<BISNIS>', '<NON ASPEK>'] \n",
      "\n",
      "['pelayanan', 'bukalapak', 'penjual', 'jelek', 'bukadompet', 'dibekukan', 'komplain', 'berulang', 'bukti', 'transaksi', 'valid', 'dibekukan', 'hasil', 'penjualan', 'ditahan', 'mohon', 'aktifkan', 'bukadompet', '<LAYANAN>', '<FITUR>', '<KEBERMANFAATAN>', '<BISNIS>', '<NON ASPEK>'] \n",
      "\n",
      "['bukalapak', 'bagus', 'barang', 'sesuai', 'pengiriman', 'cepat', 'tingkatkan', 'admin', 'biar', 'semangat', 'belanja', 'bukalapak', 'hahaha', '<LAYANAN>', '<FITUR>', '<KEBERMANFAATAN>', '<BISNIS>', '<NON ASPEK>']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Membuat Token aspek\n",
    "token_aspek = ['<LAYANAN>', '<FITUR>', '<KEBERMANFAATAN>', '<BISNIS>', '<NON ASPEK>']\n",
    "\n",
    "print(f\"\"\"Sebelum Stopword Removal:\n",
    "{ulasan_1} \\n\n",
    "{ulasan_2} \\n\n",
    "{ulasan_3} \\n\n",
    "{ulasan_4} \\n\n",
    "{ulasan_5} \n",
    "\"\"\")\n",
    "\n",
    "gabungan_tanpa_token_aspek = ulasan_1 + ulasan_2 + ulasan_3 + ulasan_4 + ulasan_5\n",
    "\n",
    "# Penambahan token aspek\n",
    "ulasan_1.extend(token_aspek)\n",
    "ulasan_2.extend(token_aspek)\n",
    "ulasan_3.extend(token_aspek)\n",
    "ulasan_4.extend(token_aspek)\n",
    "ulasan_5.extend(token_aspek)\n",
    "\n",
    "print(\"=\"*130, '\\n')\n",
    "print(f\"\"\"Setelah Stopword Removal:\n",
    "{ulasan_1} \\n\n",
    "{ulasan_2} \\n\n",
    "{ulasan_3} \\n\n",
    "{ulasan_4} \\n\n",
    "{ulasan_5}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pembangunan Kamus Corpus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setelah Penambahan Token Aspek:\n",
      "['senang', 'belanja', 'online', 'belanja', 'tidak_pernah', 'tertipu', 'penjualnya', 'jujur', 'ramah', 'layanan', 'pelanggan', 'sopan', 'kendala', 'beda', 'toko', 'online', 'shop', 'sebelah', 'tertipu', 'dionline', 'shop', 'sebelah', 'online', 'shope', 'nyaman', 'belanja', 'apapun', 'kesal', 'serbu', 'seru', 'belum_pernah', 'barang', '<LAYANAN>', '<FITUR>', '<KEBERMANFAATAN>', '<BISNIS>', '<NON ASPEK>'] \n",
      "\n",
      "['aplikasi', 'bermanfaat', 'membantu', 'jaman', 'mudah', 'cepat', '<LAYANAN>', '<FITUR>', '<KEBERMANFAATAN>', '<BISNIS>', '<NON ASPEK>'] \n",
      "\n",
      "['top', 'fitur', 'harganya', 'bermanfaat', 'sukses', 'bukalapak', 'excelent', 'nomor', 'wahid', '<LAYANAN>', '<FITUR>', '<KEBERMANFAATAN>', '<BISNIS>', '<NON ASPEK>'] \n",
      "\n",
      "['pelayanan', 'bukalapak', 'penjual', 'jelek', 'bukadompet', 'dibekukan', 'komplain', 'berulang', 'bukti', 'transaksi', 'valid', 'dibekukan', 'hasil', 'penjualan', 'ditahan', 'mohon', 'aktifkan', 'bukadompet', '<LAYANAN>', '<FITUR>', '<KEBERMANFAATAN>', '<BISNIS>', '<NON ASPEK>'] \n",
      "\n",
      "['bukalapak', 'bagus', 'barang', 'sesuai', 'pengiriman', 'cepat', 'tingkatkan', 'admin', 'biar', 'semangat', 'belanja', 'bukalapak', 'hahaha', '<LAYANAN>', '<FITUR>', '<KEBERMANFAATAN>', '<BISNIS>', '<NON ASPEK>']\n",
      "\n",
      "================================================================================================================================== \n",
      "\n",
      "Gabungan Token:\n",
      "['senang', 'belanja', 'online', 'belanja', 'tidak_pernah', 'tertipu', 'penjualnya', 'jujur', 'ramah', 'layanan', 'pelanggan', 'sopan', 'kendala', 'beda', 'toko', 'online', 'shop', 'sebelah', 'tertipu', 'dionline', 'shop', 'sebelah', 'online', 'shope', 'nyaman', 'belanja', 'apapun', 'kesal', 'serbu', 'seru', 'belum_pernah', 'barang', '<LAYANAN>', '<FITUR>', '<KEBERMANFAATAN>', '<BISNIS>', '<NON ASPEK>', 'aplikasi', 'bermanfaat', 'membantu', 'jaman', 'mudah', 'cepat', '<LAYANAN>', '<FITUR>', '<KEBERMANFAATAN>', '<BISNIS>', '<NON ASPEK>', 'top', 'fitur', 'harganya', 'bermanfaat', 'sukses', 'bukalapak', 'excelent', 'nomor', 'wahid', '<LAYANAN>', '<FITUR>', '<KEBERMANFAATAN>', '<BISNIS>', '<NON ASPEK>', 'pelayanan', 'bukalapak', 'penjual', 'jelek', 'bukadompet', 'dibekukan', 'komplain', 'berulang', 'bukti', 'transaksi', 'valid', 'dibekukan', 'hasil', 'penjualan', 'ditahan', 'mohon', 'aktifkan', 'bukadompet', '<LAYANAN>', '<FITUR>', '<KEBERMANFAATAN>', '<BISNIS>', '<NON ASPEK>', 'bukalapak', 'bagus', 'barang', 'sesuai', 'pengiriman', 'cepat', 'tingkatkan', 'admin', 'biar', 'semangat', 'belanja', 'bukalapak', 'hahaha', '<LAYANAN>', '<FITUR>', '<KEBERMANFAATAN>', '<BISNIS>', '<NON ASPEK>'] \n",
      "\n",
      "Panjang Token: 103\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"Setelah Penambahan Token Aspek:\n",
    "{ulasan_1} \\n\n",
    "{ulasan_2} \\n\n",
    "{ulasan_3} \\n\n",
    "{ulasan_4} \\n\n",
    "{ulasan_5}\n",
    "\"\"\")\n",
    "\n",
    "token_gabungan = ulasan_1 + ulasan_2 + ulasan_3 + ulasan_4 + ulasan_5\n",
    "\n",
    "print(\"=\"*130, '\\n')\n",
    "print(f\"\"\"Gabungan Token:\n",
    "{token_gabungan} \n",
    "\"\"\")\n",
    "\n",
    "print(f\"Panjang Token: {len(token_gabungan)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kamus Corpus: \n",
      "{'<pad>': 0, 'senang': 1, 'belanja': 2, 'online': 3, 'tidak_pernah': 4, 'tertipu': 5, 'penjualnya': 6, 'jujur': 7, 'ramah': 8, 'layanan': 9, 'pelanggan': 10, 'sopan': 11, 'kendala': 12, 'beda': 13, 'toko': 14, 'shop': 15, 'sebelah': 16, 'dionline': 17, 'shope': 18, 'nyaman': 19, 'apapun': 20, 'kesal': 21, 'serbu': 22, 'seru': 23, 'belum_pernah': 24, 'barang': 25, 'aplikasi': 26, 'bermanfaat': 27, 'membantu': 28, 'jaman': 29, 'mudah': 30, 'cepat': 31, 'top': 32, 'fitur': 33, 'harganya': 34, 'sukses': 35, 'bukalapak': 36, 'excelent': 37, 'nomor': 38, 'wahid': 39, 'pelayanan': 40, 'penjual': 41, 'jelek': 42, 'bukadompet': 43, 'dibekukan': 44, 'komplain': 45, 'berulang': 46, 'bukti': 47, 'transaksi': 48, 'valid': 49, 'hasil': 50, 'penjualan': 51, 'ditahan': 52, 'mohon': 53, 'aktifkan': 54, 'bagus': 55, 'sesuai': 56, 'pengiriman': 57, 'tingkatkan': 58, 'admin': 59, 'biar': 60, 'semangat': 61, 'hahaha': 62, '<LAYANAN>': 63, '<FITUR>': 64, '<KEBERMANFAATAN>': 65, '<BISNIS>': 66, '<NON ASPEK>': 67, '<UNKNOWN>': 68}\n"
     ]
    }
   ],
   "source": [
    "# Formal\n",
    "# kamus_corpus, index = {}, 1  # start indexing from 1\n",
    "# kamus_corpus['<pad>'] = 0  # add a padding token\n",
    "\n",
    "# for token in token_gabungan:\n",
    "#     if token not in kamus_corpus:\n",
    "#         kamus_corpus[token] = index\n",
    "#         index += 1\n",
    "        \n",
    "# vocab_size = len(kamus_corpus)\n",
    "# print(kamus_corpus)\n",
    "\n",
    "# Buat Latihan\n",
    "gabungan_tanpa_token_aspek.extend(token_aspek)\n",
    "gabungan_tanpa_token_aspek.append(\"<UNKNOWN>\")\n",
    "\n",
    "index, kamus_corpus = 1, {}   # start indexing from 1\n",
    "kamus_corpus['<pad>'] = 0  # add a padding token\n",
    "\n",
    "for token in gabungan_tanpa_token_aspek:\n",
    "    if token not in kamus_corpus:\n",
    "        kamus_corpus[token] = index\n",
    "        index += 1\n",
    "        \n",
    "vocab_size = len(kamus_corpus)\n",
    "print(f\"\"\"Kamus Corpus: \n",
    "{kamus_corpus}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admin' 'aktifkan' 'apapun' 'aplikasi' 'aspek' 'bagus' 'barang' 'beda'\n",
      " 'belanja' 'belum_pernah' 'bermanfaat' 'berulang' 'biar' 'bisnis'\n",
      " 'bukadompet' 'bukalapak' 'bukti' 'cepat' 'dibekukan' 'dionline' 'ditahan'\n",
      " 'excelent' 'fitur' 'hahaha' 'harganya' 'hasil' 'jaman' 'jelek' 'jujur'\n",
      " 'kebermanfaatan' 'kendala' 'kesal' 'komplain' 'layanan' 'membantu'\n",
      " 'mohon' 'mudah' 'nomor' 'non' 'nyaman' 'online' 'pelanggan' 'pelayanan'\n",
      " 'pengiriman' 'penjual' 'penjualan' 'penjualnya' 'ramah' 'sebelah'\n",
      " 'semangat' 'senang' 'serbu' 'seru' 'sesuai' 'shop' 'shope' 'sopan'\n",
      " 'sukses' 'tertipu' 'tidak_pernah' 'tingkatkan' 'toko' 'top' 'transaksi'\n",
      " 'valid' 'wahid']\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "corpus = ['senang belanja online tidak_pernah tertipu penjualnya jujur ramah layanan pelanggan sopan kendala <LAYANAN> tertipu']\n",
    "VEKTOR = vectorizer.fit_transform(token_gabungan)\n",
    "print(vectorizer.get_feature_names_out())\n",
    "\n",
    "panjang_vektor = len(vectorizer.get_feature_names_out())\n",
    "\n",
    "print(VEKTOR.toarray())\n",
    "\n",
    "print(panjang_vektor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n",
      "[[19], [7], [9], [7], [20, 10], [11], [21], [22], [23], [1], [24], [25], [26], [27], [28], [9], [12], [13], [11], [29], [12], [13], [9], [30], [31], [7], [32], [33], [34], [35], [36, 10], [14], [1], [2], [3], [4], [5, 6], [37], [15], [38], [39], [40], [16], [1], [2], [3], [4], [5, 6], [41], [2], [42], [15], [43], [8], [44], [45], [46], [1], [2], [3], [4], [5, 6], [47], [8], [48], [49], [17], [18], [50], [51], [52], [53], [54], [18], [55], [56], [57], [58], [59], [17], [1], [2], [3], [4], [5, 6], [8], [60], [14], [61], [62], [16], [63], [64], [65], [66], [7], [8], [67], [1], [2], [3], [4], [5, 6]]\n",
      "\n",
      "\n",
      "Word Index: \n",
      " {'layanan': 1, 'fitur': 2, 'kebermanfaatan': 3, 'bisnis': 4, 'non': 5, 'aspek': 6, 'belanja': 7, 'bukalapak': 8, 'online': 9, 'pernah': 10, 'tertipu': 11, 'shop': 12, 'sebelah': 13, 'barang': 14, 'bermanfaat': 15, 'cepat': 16, 'bukadompet': 17, 'dibekukan': 18, 'senang': 19, 'tidak': 20, 'penjualnya': 21, 'jujur': 22, 'ramah': 23, 'pelanggan': 24, 'sopan': 25, 'kendala': 26, 'beda': 27, 'toko': 28, 'dionline': 29, 'shope': 30, 'nyaman': 31, 'apapun': 32, 'kesal': 33, 'serbu': 34, 'seru': 35, 'belum': 36, 'aplikasi': 37, 'membantu': 38, 'jaman': 39, 'mudah': 40, 'top': 41, 'harganya': 42, 'sukses': 43, 'excelent': 44, 'nomor': 45, 'wahid': 46, 'pelayanan': 47, 'penjual': 48, 'jelek': 49, 'komplain': 50, 'berulang': 51, 'bukti': 52, 'transaksi': 53, 'valid': 54, 'hasil': 55, 'penjualan': 56, 'ditahan': 57, 'mohon': 58, 'aktifkan': 59, 'bagus': 60, 'sesuai': 61, 'pengiriman': 62, 'tingkatkan': 63, 'admin': 64, 'biar': 65, 'semangat': 66, 'hahaha': 67} \n",
      "\n",
      "Panjang Korpus: 67 \n",
      "\n",
      "Corpus :\n",
      "[[19], [7], [9], [7], [20, 10], [11], [21], [22], [23], [1], [24], [25], [26], [27], [28], [9], [12], [13], [11], [29], [12], [13], [9], [30], [31], [7], [32], [33], [34], [35], [36, 10], [14], [1], [2], [3], [4], [5, 6], [37], [15], [38], [39], [40], [16], [1], [2], [3], [4], [5, 6], [41], [2], [42], [15], [43], [8], [44], [45], [46], [1], [2], [3], [4], [5, 6], [47], [8], [48], [49], [17], [18], [50], [51], [52], [53], [54], [18], [55], [56], [57], [58], [59], [17], [1], [2], [3], [4], [5, 6], [8], [60], [14], [61], [62], [16], [63], [64], [65], [66], [7], [8], [67], [1], [2], [3], [4], [5, 6]]\n"
     ]
    }
   ],
   "source": [
    "# Pembuatan Korpus menggunakan \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(token_gabungan)\n",
    "\n",
    "training_korpus = tokenizer.texts_to_sequences(token_gabungan)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)\n",
    "\n",
    "print(training_korpus)\n",
    "\n",
    "# training_korpus = tokenizer.texts_to_sequences(test_korpus)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('\\n')\n",
    "print('Word Index: \\n',word_index, '\\n')\n",
    "\n",
    "vocab_size = len(tokenizer.word_counts)\n",
    "print(f\"Panjang Korpus: {vocab_size} \\n\")\n",
    "\n",
    "print(f\"\"\"Corpus :\n",
    "{training_korpus}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriks X * W1 = \n",
      " [[0.29589605 0.87511652 0.34923644]] \n",
      "\n",
      "Wo = \n",
      " [[8.88563979e-01 2.18313935e-01 5.80796934e-01 6.81545213e-01\n",
      "  9.27491848e-01 5.76521000e-02 9.64854707e-01 5.70784865e-04\n",
      "  7.81632570e-01 9.64367105e-01 9.84719886e-02 6.52514638e-01\n",
      "  6.10215722e-01 9.64043033e-01 5.35003014e-01 8.55455729e-01\n",
      "  7.16816838e-01 9.72308253e-01 1.17566238e-01 1.79785149e-02\n",
      "  1.14566126e-01 2.37463239e-01 2.97068782e-01 6.67025402e-01\n",
      "  5.58042552e-01 8.18564427e-01 1.40570123e-01 3.89408886e-01\n",
      "  5.41926877e-01 6.37492362e-01 1.20435536e-01 7.61205275e-01\n",
      "  7.29194093e-02 1.66073093e-01 3.16652429e-01 8.32194259e-02\n",
      "  9.31314439e-01 2.94830136e-01 2.91981828e-01 4.92446419e-01\n",
      "  3.07499481e-01 7.47951628e-01 4.14038647e-01 5.05714070e-01\n",
      "  8.43100794e-01 9.41210144e-01 6.32507188e-01 1.78042901e-01\n",
      "  7.82602892e-01 9.89205177e-01 9.67793287e-01 7.84785049e-01\n",
      "  7.97204574e-01 5.17966113e-01 1.71741491e-01 9.13320487e-01\n",
      "  9.22966042e-01 7.33539578e-01 6.56804549e-01 4.20937755e-01\n",
      "  7.61828746e-01 2.28489252e-01 3.90532826e-01 4.02222605e-01\n",
      "  9.61791113e-01 4.94101603e-02 4.53077906e-01 9.62461829e-01]\n",
      " [9.74344794e-01 7.51722890e-01 7.63469076e-01 3.04551548e-01\n",
      "  2.66194052e-01 5.44718235e-01 4.84716209e-01 7.15274222e-01\n",
      "  6.54541486e-01 6.36167560e-01 5.05765666e-01 3.18309637e-01\n",
      "  7.34831340e-02 3.37399719e-01 3.11282191e-01 8.74351079e-02\n",
      "  5.07966776e-01 4.61180240e-01 4.01530773e-01 7.28337942e-01\n",
      "  2.68489813e-01 8.89556242e-01 1.60452714e-01 7.98622281e-01\n",
      "  3.16890232e-01 5.17358630e-02 5.36946347e-01 4.61798503e-01\n",
      "  6.70207241e-02 4.32349818e-01 2.80191631e-01 2.39835814e-01\n",
      "  8.00880855e-01 2.70725850e-01 4.66526423e-01 1.91460059e-01\n",
      "  3.35043914e-01 7.21889536e-01 4.41002584e-01 1.30566990e-01\n",
      "  3.67033784e-01 8.97241651e-01 7.95304773e-01 7.80801453e-02\n",
      "  2.25855755e-02 6.03599615e-01 5.27312552e-01 8.48439522e-01\n",
      "  5.30950278e-01 6.59536477e-01 5.17126337e-01 1.74220712e-01\n",
      "  4.26183106e-01 4.98545071e-01 2.05441504e-01 2.53002971e-01\n",
      "  4.38193364e-01 5.93906753e-01 3.38847261e-01 1.71643680e-01\n",
      "  2.50883493e-02 8.59470947e-03 4.99375376e-01 7.44859738e-01\n",
      "  3.73017199e-01 9.57838872e-01 4.55505000e-02 8.22064789e-01]\n",
      " [5.29292106e-01 7.70768907e-01 7.16704241e-01 3.33990174e-01\n",
      "  3.28071867e-01 6.15717807e-01 8.33257820e-01 6.62527406e-01\n",
      "  1.27911795e-01 7.84794397e-01 1.66702010e-01 7.96402444e-01\n",
      "  5.22419049e-01 2.57642549e-01 4.58313555e-01 4.46523581e-01\n",
      "  3.11612839e-02 4.73591138e-01 3.20492825e-01 2.91320400e-01\n",
      "  5.67305642e-01 8.02240668e-01 2.72989987e-01 3.52542530e-01\n",
      "  8.67072540e-01 7.56553419e-01 8.16357787e-01 5.74804257e-02\n",
      "  5.73016703e-01 2.66712355e-01 4.94384140e-01 6.61991860e-01\n",
      "  4.22266790e-01 1.59985522e-01 9.60561031e-01 2.56921244e-01\n",
      "  8.30023862e-01 5.56622240e-01 2.61992024e-01 8.60443422e-01\n",
      "  9.35752899e-01 2.82287777e-01 9.30976656e-01 8.34003869e-01\n",
      "  7.68039568e-01 4.59181622e-03 3.88385661e-01 2.68289632e-01\n",
      "  7.04611281e-03 5.90923571e-01 2.53716820e-01 2.07409835e-01\n",
      "  8.78748392e-01 4.34988662e-01 6.85927767e-01 3.68389631e-01\n",
      "  6.42725453e-01 9.51115181e-01 5.20645686e-01 8.26746356e-01\n",
      "  8.66585417e-01 6.59977735e-01 5.88991718e-01 4.68734347e-01\n",
      "  4.43635953e-01 9.22646908e-01 2.23169235e-01 6.72757537e-03]] \n",
      "\n",
      "hasil: \n",
      " [[1.30043588 0.99162394 1.09027915 0.58482616 0.62196663 0.70878205\n",
      "  1.00068385 0.85749589 0.84875352 1.11615196 0.52995978 0.74976728\n",
      "  0.42731449 0.67049876 0.59077326 0.48558418 0.66751604 0.8566839\n",
      "  0.49810137 0.74444004 0.46698334 1.12890147 0.32365435 1.01937843\n",
      "  0.74525179 0.55170091 0.79658665 0.53942631 0.41912328 0.66013361\n",
      "  0.45349368 0.66631359 0.86991158 0.34192981 0.83742409 0.28190042\n",
      "  0.8586493  0.9133693  0.56382208 0.56047247 0.73898422 1.1050921\n",
      "  1.14362771 0.50923256 0.5374626  0.80832399 0.78425473 0.88886215\n",
      "  0.69867322 1.07624521 0.82751917 0.45711329 0.91574052 0.74146304\n",
      "  0.47015385 0.62031008 0.8810354  1.06895315 0.67270515 0.56349199\n",
      "  0.55002055 0.30561871 0.75826613 0.93455426 0.76595754 1.17506281\n",
      "  0.25186479 1.00654064]] \n",
      "\n",
      "Dimensi Hasil Matriks (1, 68)\n"
     ]
    }
   ],
   "source": [
    "# Hitung Word2Vec CBOW\n",
    "# Konteks = pelayanan, target = jelek\n",
    "x_w1 = np.array(([(0.295896048568338, 0.875116521258698, 0.349236435241011)]))\n",
    "print('Matriks X * W1 = \\n', x_w1, '\\n')\n",
    "\n",
    "wo = np.array(([0.888563979365201, 0.218313935186904, 0.580796934329850, 0.681545213455374, 0.927491847520756, 0.057652099980229, 0.964854706839704, 0.000570784865009, 0.781632570359999, 0.964367105429220, 0.098471988604675, 0.652514637920216, 0.610215722100892, 0.964043033160407, 0.535003013956565, 0.855455728652069, 0.716816837940844, 0.972308253104550, 0.117566238323095, 0.017978514903416, 0.114566126299784, 0.237463238883085, 0.297068781572555, 0.667025402287037, 0.558042551983460, 0.818564426814474, 0.140570123113170, 0.389408885580430, 0.541926876918667, 0.637492361665503, 0.120435535599047, 0.761205275353343, 0.072919409315591, 0.166073093004713, 0.316652429446665, 0.083219425917841, 0.931314438520837, 0.294830136424495, 0.291981827717498, 0.492446418745864, 0.307499481429108, 0.747951627690622, 0.414038647108478, 0.505714070395031, 0.843100793893863, 0.941210144199850, 0.632507187534394, 0.178042901444692, 0.782602892206363, 0.989205176606322, 0.967793286825441, 0.784785049188179, 0.797204574420512, 0.517966112648770, 0.171741490804255, 0.913320487158477, 0.922966041886655, 0.733539577861614, 0.656804549035976, 0.420937755432511, 0.761828746136406, 0.228489252387893, 0.390532826272719, 0.402222605074492, 0.961791113105603, 0.049410160338014, 0.453077906047781, 0.962461828896374],\n",
    "[0.974344793589976,\t0.751722890380824,\t0.763469076083616,\t0.304551547996851,\t0.266194052059271,\t0.544718234770658,\t0.484716209030235,\t0.715274222244976,\t0.654541486157574,\t0.636167560264755,\t0.505765666445419,\t0.318309637470674,\t0.073483134048993,\t0.337399718844010,\t0.311282191443645,\t0.087435107850281,\t0.507966776354144,\t0.461180240474609,\t0.401530772902720,\t0.728337941748544,\t0.268489813158173,\t0.889556241614190,\t0.160452713841916,\t0.798622281362812,\t0.316890232224549,\t0.051735862984310,\t0.536946347309393,\t0.461798503497999,\t0.067020724134713,\t0.432349817559332,\t0.280191630821428,\t0.239835813820470,\t0.800880854805450,\t0.270725850360651,\t0.466526422802128,\t0.191460058627431,\t0.335043914238249,\t0.721889536074550,\t0.441002583816223,\t0.130566990213852,\t0.367033784265990,\t0.897241650851948,\t0.795304772873041,\t0.078080145255067,\t0.022585575514360,\t0.603599614703498,\t0.527312552458811,\t0.848439522477953,\t0.530950277591858,\t0.659536477269735,\t0.517126337014028,\t0.174220711616174,\t0.426183106005842,\t0.498545071305308,\t0.205441503854195,\t0.253002970797249,\t0.438193363626917,\t0.593906752915362,\t0.338847260716643,\t0.171643679728545,\t0.025088349305311,\t0.008594709473533,\t0.499375376368382,\t0.744859738473849,\t0.373017199247224,\t0.957838871990445,\t0.045550500039313,\t0.822064789041146],\n",
    "[0.529292105839121,\t0.770768907365604,\t0.716704240994275,\t0.333990174273797,\t0.328071866660900,\t0.615717807054809,\t0.833257819661222,\t0.662527405812146,\t0.127911795206998,\t0.784794397354449,\t0.166702010471746,\t0.796402444086605,\t0.522419049163537,\t0.257642549222496,\t0.458313554899391,\t0.446523580738361,\t0.031161283880481,\t0.473591137687783,\t0.320492824553229,\t0.291320400350903,\t0.567305641514417,\t0.802240668029179,\t0.272989987178495,\t0.352542530479943,\t0.867072540237627,\t0.756553419099302,\t0.816357786793103,\t0.057480425733755,\t0.573016702727897,\t0.266712355406567,\t0.494384140033599,\t0.661991860064933,\t0.422266789695167,\t0.159985522405666,\t0.960561030973873,\t0.256921243921245,\t0.830023862323862,\t0.556622239685314,\t0.261992023787515,\t0.860443421991516,\t0.935752898941041,\t0.282287777370737,\t0.930976656130412,\t0.834003869129923,\t0.768039567712267,\t0.004591816217233,\t0.388385660861922,\t0.268289631916889,\t0.007046112811189,\t0.590923570806926,\t0.253716820005544,\t0.207409834878488,\t0.878748391719332,\t0.434988662136596,\t0.685927767070524,\t0.368389630523654,\t0.642725453367186,\t0.951115181431175,\t0.520645685942289,\t0.826746356219077,\t0.866585417032627,\t0.659977734955393,\t0.588991718438790,\t0.468734347180679,\t0.443635953096195,\t0.922646908133139,\t0.223169234942836,\t0.006727575370675]))\n",
    "\n",
    "print('Wo = \\n', wo,'\\n')\n",
    "\n",
    "# perkalian matriksnya\n",
    "hasil_kali_matriks = np.dot(x_w1, wo)\n",
    "print(\"hasil: \\n\", hasil_kali_matriks, '\\n')\n",
    "print(\"Dimensi Hasil Matriks\", hasil_kali_matriks.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eksponensial : \n",
      " [[3.67089641 2.69560842 2.97510447 1.79467898 1.86258747 2.03151546\n",
      "  2.72014136 2.35725049 2.33673234 3.05308317 1.69886398 2.1165074\n",
      "  1.53313474 1.95521225 1.8053839  1.6251241  1.9493891  2.35533719\n",
      "  1.64559393 2.10526223 1.59517482 3.09225769 1.38216948 2.77147157\n",
      "  2.10697188 1.73620363 2.21795732 1.71502269 1.5206278  1.93505086\n",
      "  1.57380095 1.94704647 2.38669981 1.40766149 2.31040791 1.3256467\n",
      "  2.35997093 2.49270708 1.75737651 1.75149984 2.09380758 3.01950255\n",
      "  3.13813199 1.66401367 1.71165819 2.24414362 2.19077361 2.43236041\n",
      "  2.01108268 2.93364364 2.28763645 1.57950782 2.49862484 2.09900421\n",
      "  1.60024037 1.85950456 2.41339725 2.91232913 1.95953098 1.75679652\n",
      "  1.73328863 1.35746462 2.13457194 2.5460783  2.15105311 3.23834634\n",
      "  1.28642208 2.73611942]] \n",
      "\n",
      "Sum Eksponensial: 145.26216732349076  \n",
      "\n",
      "Probabilitas Softmax \n",
      " [[0.02527084 0.01855685 0.02048093 0.01235476 0.01282225 0.01398517\n",
      "  0.01872574 0.01622756 0.01608631 0.02101774 0.01169516 0.01457026\n",
      "  0.01055426 0.01345989 0.01242845 0.01118752 0.0134198  0.01621439\n",
      "  0.01132844 0.01449285 0.01098135 0.02128743 0.009515   0.0190791\n",
      "  0.01450462 0.01195221 0.01526865 0.0118064  0.01046816 0.01332109\n",
      "  0.01083421 0.01340367 0.01643029 0.00969049 0.01590509 0.00912589\n",
      "  0.01624629 0.01716006 0.01209796 0.01205751 0.01441399 0.02078657\n",
      "  0.02160323 0.01145524 0.01178323 0.01544892 0.01508152 0.01674462\n",
      "  0.0138445  0.02019551 0.01574833 0.0108735  0.0172008  0.01444977\n",
      "  0.01101622 0.01280102 0.01661408 0.02004878 0.01348962 0.01209397\n",
      "  0.01193214 0.00934493 0.01469462 0.01752747 0.01480808 0.02229312\n",
      "  0.00885586 0.01883573]] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eksponensialkan = np.exp(hasil_kali_matriks)\n",
    "print('Eksponensial : \\n', eksponensialkan, '\\n')\n",
    "\n",
    "print(f\"Sum Eksponensial: {np.sum(eksponensialkan)} \", '\\n')\n",
    "\n",
    "probabilitas_softmax = eksponensialkan / np.sum(eksponensialkan)\n",
    "print('Probabilitas Softmax \\n', probabilitas_softmax, '\\n')\n",
    "\n",
    "# Maka jika probabilitas masing-masing dijumlahkan hasilnya akan bernilai satu\n",
    "probabilitas_softmax.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5fb9e22d6cb474a5f05f245ce1471996f9d1b79ec2fc1a71ea989e0e63213d9f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
